{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-a2dc3e4a-61f0-4121-9c86-813062db9ea5",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "<p class=\"title\"> CS107 Final Project</p>\n",
    "\n",
    "<p class=\"subtitle\">Group 29</p>\n",
    "\n",
    "<center>\n",
    "\n",
    "<p class=\"gap05\"<p>\n",
    "<h2>SocialAD Package</h2>\n",
    "\n",
    "<p class=\"gap05\"<p>\n",
    "<h3> Ju Chulakadabba, Dashiell Young-Saver, Tao Tsui, Jenny Wang\n",
    "</h3>\n",
    "<h3>Harvard University</h3>\n",
    "\n",
    "<p class=\"gap2\"<p>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-2c4ce61b-5a22-40a0-986a-2d37db85580f",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "## Section I: Introduction to socialAD\n",
    "\n",
    "Our software provides users with functions that find roots and stationary points of equations. \n",
    "The algorithms implemented are powered by automatic differentiation (forward mode). \n",
    "\n",
    "\n",
    "Automatic differentiation allows our alogrithms to solve derivatives quickly and to machine precision, \n",
    "which means our root and stationary finding algorithms are more efficient than many packages built on finite difference methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-be5819dc-ad7a-4702-b378-b229b8d28cc4",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Background\n",
    "\n",
    "- Finding Roots\n",
    "    - **Newton's Method**\n",
    "    - **Broyden's Method**\n",
    "\n",
    "- Finding Minima\n",
    "    - **Gradient Descent**\n",
    "    - **Broyden–Fletcher–Goldfarb–Shanno (BFGS)**\n",
    "\n",
    "All of these methods require finding derivatives, a Jacobian, or a Jacobian approximation!    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-b345f6a0-1c73-49f6-b3ec-66940c65fe1d",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Automatic Differentiation \n",
    "\n",
    "- Used to power our package, automatic differentiation (forward mode) uses the chain rule to step through complex functions and calculate derivatives.\n",
    "- Users can use the forward mode of our automatic differentiation methods for their own purposes (outside of our root-finding algorithms), if desired\n",
    "- Our package also computes second-order derivatives, for use in finding local minima and maxima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-571e5cbd-75b6-43d5-b1d4-84e0adce4c57",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## A Deriviate We May Have to Evaluate\n",
    "\n",
    "$~$\n",
    "\n",
    "\n",
    "$$f(x,y)=\\begin{bmatrix} x^2+y^2 \\\\ \\exp(x+y) \\end{bmatrix}.$$\n",
    "\n",
    "$$J=\\begin{bmatrix} \\partial f_{1} / \\partial x & \\partial f_{1} / \\partial y \\\\ \\partial f_{2} / \\partial x & \\partial f_{2} / \\partial y \\end{bmatrix}=\\begin{bmatrix} 2x & 2y \\\\ \\exp(x+y) & \\exp(x+y) \\end{bmatrix}$$\n",
    "\n",
    "$~$\n",
    "\n",
    "Evaluate it at the point (1,1):\n",
    "\n",
    "$$J=\\begin{bmatrix} 2 & 2 \\\\ 7.38906 & 7.38906 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-6c0b263d-e622-46cf-be3e-346aa50929fe",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## How can we do this to machine precision?\n",
    "\n",
    "Get the simpler derivatives on each *level* of the function, and then carry those derivatives through the whole function throught the chain rule!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-9998db40-877f-4911-83a5-0f60b2e88bde",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Using The Chain Rule for Automatic Differentiation\n",
    "\n",
    "The chain rule is used to evaluate the derivative of a function by differentiating the outer function, multiplied by the derivative of the inner function, until all layers of the function are complete.\n",
    "\n",
    "Suppose we have a function $F(x) = f(g(x))$, then $F'(x) = f'(g(x))g'(x)$.\n",
    "\n",
    "We can traverse a function $f(x)$ by following what happens to its input, $x$. We evaluate from the innermost layer and work our way outwards. For each layer, we calculate its derivative and then feed that as the input to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-0aaa705c-a225-4c5a-a710-cd46f103cd0f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## What it looks like: Trace Tables\n",
    "\n",
    "| trace   | elem op.      | value    | elem derivative          | $\\nabla_{x}$| $\\nabla_{y}$ |\n",
    "| :---:   | :------:      | :---:    | :---------------------:  | :---------: | :----------: |\n",
    "| $x_{1}$ | $x_{1}$       | $1$      | $\\dot{x}_{1}$            |    $1$      |    $0$       |\n",
    "| $x_{2}$ | $x_{2}$       | $1$     | $\\dot{x}_{2}$            | $0$         | $1$         |\n",
    "| $v_{1}$ | $x_{1}^{2}$   | $1$      | $2x_{1}\\dot{x}_{1}$      | $2$         | $0$          |\n",
    "| $v_{2}$ | $x_{2}^{2}$   | $1$      | $2x_2\\dot{x}_{2}$| $0$   | $2$        |\n",
    "| $v_{3}$ | $v_{1}+v_{2}$ | $2$      | $\\dot{v}_1+\\dot{v}_2$    | $2$         | $2$      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-a18eb32b-e192-41c3-b533-4999a491286b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Positive Broader Impacts\n",
    "\n",
    "There are multiple ways to use our package for greater scientific and social good. \n",
    "There are also ways to misuse our package in these respects.\n",
    "\n",
    "The functions we provide are widely applicable in many fields. \n",
    "- Engineers use root-finding to optimize space given material constraints. \n",
    "- Data scientists use root-finding to inform machine learning models. \n",
    "- Physicists find stationary points to map particle motion.\n",
    "- Economists find stationary points to describe changing markets.\n",
    "\n",
    "To the extent that fields may use our package to spur innovation, solve problems that help humanity, \n",
    "create a more efficient workforce and economy, and work towards a more advanced and just world - we will \n",
    "be proud our package made some contribution to these efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-d8f3f1ae-b4e9-4169-a08f-4654d8f5375e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Potential Negative Broader Impact\n",
    "\n",
    "However, alongside innovation can come consequences. \n",
    "\n",
    "For example, \n",
    "our gradient descement implementations may be used in machine learning implementations, which sometimes have been used in negative contexts:\n",
    "- Introducing bias in \n",
    "[policing and in court systems](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)\n",
    "- Taking [jobs away](https://time.com/5876604/machines-jobs-coronavirus/) from the service industry\n",
    "  (and others)\n",
    "- Accelerated new ways of [illegal hacking](https://techhq.com/2020/09/how-hackers-are-weaponizing-artificial-intelligence/). \n",
    "\n",
    "In addition, fields of science that could utilize our package and that spur technological innovation (such as physics) \n",
    "  can also spur great human loss with that innovation (such as the invention of the atomic bomb - as one historic example). \n",
    "  We strongly encourage those who use our package to consider the consequences of their work, especially as they apply their \n",
    "  work to contexts that are prone to the types of issues mentioned above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-6fa52299-5f9f-41da-bc8d-5e939616f554",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Software Inclusivity\n",
    "\n",
    "Our package is open-source on GitHub, and pull requests can be made by anyone who has a free GitHub account. \n",
    "The package authors (Tao, Jenny, Ju, and Dash) will approve pull requests after collectively discussing the impact of\n",
    " those pull requests. We will review pull requests without viewing the personal details of user accounts who make them, \n",
    " thus preventing some level of bias in our decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-8320fb73-189e-4263-bb4d-80531d0dca99",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "## Section II: Implementation\n",
    "\n",
    "### Installation\n",
    "\n",
    "Our package is on _pip_. You can open up a terminal and run the following in your work environment:\n",
    "\n",
    "`$ pip install socialAD`\n",
    "\n",
    "To upgrade the package on your local machine, please run:\n",
    "\n",
    "`$ pip install socialAD --upgrade`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-f15bdaf0-aada-425e-b086-cb1cc121e970",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Software Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-f7c216d5-c518-4990-98d4-0d70e4baba3c",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "General structure of our package:\n",
    "\n",
    "![software_orgo](./img/software_orgo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-b5db3636-fbea-4693-8f26-40c9b3d5f645",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "`/socialAD` contains scripts for all of our base classes and extensions:\n",
    "* `forward.py`: basic implementation of forward mode\n",
    "* `root_finding.py`: Broyden function\n",
    "* `gradient.py`: gradient descent\n",
    "* `forward_pro.py`: second derivatives\n",
    "\n",
    "`/tests` contains all of our tests\n",
    "* `/runtests.py` executes the tests\n",
    "\n",
    "`/docs` contains documentation\n",
    "\n",
    "#### For developers\n",
    "\n",
    "First, clone the repository to your local machine:\n",
    "\n",
    "`$ git clone https://github.com/climate-change-is-real-python-dev/cs107-FinalProject.git`\n",
    "\n",
    "\n",
    "Go to the repository:\n",
    "\n",
    "`$ cd /path/to/cs107-FinalProject`\n",
    "\n",
    "\n",
    "##### Installing dependencies\n",
    "\n",
    "`$ pip install -r requirements.txt`\n",
    "\n",
    "\n",
    "##### Running unit tests\n",
    "\n",
    "Say you have written an optimization function and would like to test it. You can create a unit test file called `optimization_tests.py` in the `tests` folder:\n",
    "\n",
    "`$ cd /path/to/cs107-FinalProject/tests`\n",
    "\n",
    "\n",
    "`$ touch optimization_tests.py`\n",
    "\n",
    "After creating test cases, head over to the top level and open `runtests.py`:\n",
    "\n",
    "`$ cd ..`\n",
    "\n",
    "\n",
    "`$ vi runtests.py`\n",
    "\n",
    "Add the following line to `runtests.py`:\n",
    "\n",
    "`$ runpy.run_path(path_name='tests/optimization_tests.py')`\n",
    "\n",
    "Stay in `cs107-FinalProject` and run:\n",
    "\n",
    "`$ chmod +x runtests.py`\n",
    "\n",
    "\n",
    "`$ ./runtests.py`\n",
    "\n",
    "Or this:\n",
    "\n",
    "`$ python runtests.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-c35bdae1-7fee-45e5-b0b7-897a6868b2c5",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Implementation Details\n",
    "\n",
    "`forwardAD` class:\n",
    "* Attributes: `.val` and `.der`\n",
    "* Arithmetic operators\n",
    "* Comparison operators\n",
    "* Elementary functions\n",
    "* Vector functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-0ce10145-9bb6-4b91-9438-2614758ef426",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### How to Use\n",
    "\n",
    "#### Scalar inputs\n",
    "\n",
    "Instantiate a `forwardAD` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00006-dfe232a6-2991-41fc-ac4e-279c7098b8ce",
    "deepnote_cell_type": "code",
    "execution_millis": 4,
    "execution_start": 1607713237131,
    "output_cleared": false,
    "source_hash": "1cf3cece",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from socialAD.forward import forwardAD\n",
    "x = forwardAD(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-9fd833c1-6f3e-4760-8cae-b3d4eeb79984",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "Write a function of `x` of your choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00009-be8ffa0b-b92e-4d95-87fb-f6a1106946bd",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1607713237159,
    "output_cleared": false,
    "source_hash": "ef395805",
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = (x + 5)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-ddfd37a5-2a9f-4767-bac2-88893c9c07fa",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "Evaluate `f` and find its derivative at `x = 3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00011-5633b355-cf4e-4908-aaa1-b829a0ad3808",
    "deepnote_cell_type": "code",
    "execution_millis": 1,
    "execution_start": 1607713237159,
    "output_cleared": false,
    "source_hash": "2d0ddc06",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function value: 64\n",
      "Derivative value: [16.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Function value: {}\".format(f.val))\n",
    "print(\"Derivative value: {}\".format(f.der))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-4d0b952f-0b00-40c7-ae18-12c860c660c2",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "![simple_val](./img/2_simple_val.jpg)\n",
    "![simple_der](./img/3_simple_der.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-ea3a7f9b-2285-4249-a058-30324e44891b",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "You can also try a more complex function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00013-fd58a478-0d60-46c1-b5c8-f58489a3b7fb",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1607713237160,
    "output_cleared": false,
    "source_hash": "b4e308ff",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function value: 9551.413159102576\n",
      "Derivative value: [9529.4131591]\n"
     ]
    }
   ],
   "source": [
    "from socialAD.forward import e\n",
    "import numpy as np\n",
    "\n",
    "# Instantiate initial input to function\n",
    "x = forwardAD(5)\n",
    "\n",
    "# Function (note: make multiplication explicit)\n",
    "f = e()**x - (2 - 6 * x - 3 * x ** 5)\n",
    "\n",
    "# Get function value at x = 5 and derivative at x = 5\n",
    "print(\"Function value: {}\".format(f.val))\n",
    "print(\"Derivative value: {}\".format(f.der))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-68377c52-da74-4559-b7f9-b663dfd9ec51",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "![complex_val](./img/4_complex_val.jpg)\n",
    "![complex_der](./img/5_complex_der.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-462fa4fb-7a30-472e-bf83-308cf6d472a6",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "#### Vector inputs\n",
    "\n",
    "Workflow to compute the values and the Jacobian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00015-0c6f4fe0-7115-4bc7-83d5-b9e6f53f57bf",
    "deepnote_cell_type": "code",
    "execution_millis": 2,
    "execution_start": 1607713237162,
    "output_cleared": false,
    "source_hash": "b3508e8e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function values: \n",
      "[[ 6]\n",
      " [13]]\n",
      "Jacobian: \n",
      "[[2. 3.]\n",
      " [6. 4.]]\n"
     ]
    }
   ],
   "source": [
    "from socialAD.forward import vector_func\n",
    "\n",
    "a = np.array([3])\n",
    "x = forwardAD(a, numvar = 2, idx = 0)\n",
    "\n",
    "b = np.array([2])\n",
    "y = forwardAD(b, numvar = 2, idx = 1)\n",
    "\n",
    "f1 = x*y\n",
    "f2 = x**2 + y**2\n",
    "\n",
    "v = vector_func(f1, f2)\n",
    "values_v = v.values\n",
    "jacobian_v = v.jacobian\n",
    "\n",
    "print(\"Function values: \\n{}\".format(values_v()))\n",
    "print(\"Jacobian: \\n{}\".format(jacobian_v()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-815e8f75-ce49-4a9b-89ff-f4ec5fd1b548",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "#### Simple root-finding use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00017-1d7a853a-ff8f-428d-8b38-02feb30b3637",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1607713237187,
    "output_cleared": false,
    "source_hash": "58a3b642",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root value: [0.14133666]\n",
      "Function value at root: [0.01088635]\n"
     ]
    }
   ],
   "source": [
    "# Initialize root value and step value\n",
    "root = 0.0\n",
    "dx = 50\n",
    "\n",
    "# While step is greater than a very small number\n",
    "while dx > 1e-20:\n",
    "\n",
    "    # Instantiate a forward AD object at root guess\n",
    "    x = forwardAD(root)\n",
    "\n",
    "    # Write our function\n",
    "    f = e()**x - (2 - 6*x - 3 * x ** 5)\n",
    "\n",
    "    # Get step using Newton's Method\n",
    "    dx = -f.val / f.der\n",
    "\n",
    "    # Save new root with new step\n",
    "    root = root + dx\n",
    "    \n",
    "print(\"Root value: {}\".format(root))\n",
    "print(\"Function value at root: {}\".format(f.val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-a91b8104-2482-485e-9b47-4a51183da388",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "![complex_root1](./img/6_complex_root1.jpg)\n",
    "![complex_root1](./img/6_complex_root2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-f3ebc013-de8a-4201-aac9-124d22796626",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "#### Comparison operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00020-b20395ce-383f-43f6-b6a2-da7edcf60e68",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1607713237188,
    "output_cleared": false,
    "source_hash": "d6ce5c8f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of f1: 37\n",
      "Value of f2: 40\n",
      "Derivative of f1: [7.]\n",
      "Derivative of f2: [7.]\n",
      "\n",
      "\n",
      "Equality: False\n",
      "Inequality: False\n",
      "Less than: [False]\n",
      "Less than or equal to: [ True]\n",
      "Greater than: False\n",
      "Greater than or equal to: False\n"
     ]
    }
   ],
   "source": [
    "x = forwardAD(4)\n",
    "y = forwardAD(7)\n",
    "f1 = 4*x + 3*y\n",
    "f2 = 3*x + 4*y\n",
    "\n",
    "print(\"Value of f1: {}\".format(f1.val))\n",
    "print(\"Value of f2: {}\".format(f2.val))\n",
    "print(\"Derivative of f1: {}\".format(f1.der))\n",
    "print(\"Derivative of f2: {}\".format(f2.der))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# For equality and inequality, true only if both val and der are true\n",
    "print(\"Equality: {}\".format(f1 == f2)) # Expected: val false, der true, therefore false\n",
    "print(\"Inequality: {}\".format(f1 != f2)) # Expected: val true, der false, therefore false\n",
    "print(\"Less than: {}\".format(f1 < f2)) # Expected: val true, der false, therefore false\n",
    "print(\"Less than or equal to: {}\".format(f1 <= f2)) # Expected: val true, der true, therefore true\n",
    "print(\"Greater than: {}\".format(f1 > f2)) # Expected: val false, der false, therefore false\n",
    "print(\"Greater than or equal to: {}\".format(f1 >= f2)) # Expected: val false, der true, therefore false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-12e3026c-5584-48be-992e-d8ed6c743ae2",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "## Section III: Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-e1725c29-411d-46d5-89d8-ae57d21ca107",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### 2nd-order Derivatives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00034-dccd422a-9901-450f-9a78-9bd6632d20a0",
    "deepnote_cell_type": "code",
    "execution_millis": 10,
    "execution_start": 1607738308754,
    "output_cleared": false,
    "source_hash": "ae1160bf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Value:  2.8949439051408983\n",
      "1st Derivative:  -7.523384839521769\n",
      "2nd Derivative:  [20.48755358]\n"
     ]
    }
   ],
   "source": [
    "from socialAD.forward_pro import *\n",
    "\n",
    "#from forward_pro import *\n",
    "\n",
    "x = forwardAD_pro(0.387)\n",
    "f = log(1/(arctan(x)*x**2))\n",
    "\n",
    "print(\"Function Value: \", f.func.val)\n",
    "print(\"1st Derivative: \", f.dera.val)\n",
    "print(\"2nd Derivative: \", f.dera.der)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00036-6f521852-c2c3-49cf-a97d-5daf835aa7f0",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "![complex_root1](./img/2nd_der_1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00039-fd676ebf-e3d0-4929-b9b9-e290a69e4e04",
    "deepnote_cell_type": "code",
    "execution_millis": 3,
    "execution_start": 1607738630431,
    "output_cleared": false,
    "source_hash": "da59b4df",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Value:  -1.5055671924729173\n",
      "1st Derivative:  1.7564520982201164\n",
      "2nd Derivative:  [-6.08601388]\n"
     ]
    }
   ],
   "source": [
    "x = forwardAD_pro(0.387)\n",
    "f = e()**x*log(x**3/(cosh(x)*x**2))\n",
    "\n",
    "print(\"Function Value: \", f.func.val)\n",
    "print(\"1st Derivative: \", f.dera.val)\n",
    "print(\"2nd Derivative: \", f.dera.der)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00038-367e088a-813c-4f2e-b633-8ca055d716fd",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "![complex_root1](./img/2nd_der_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00039-0f044eb2-eb19-4492-9419-d9624dd05434",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Root-finding Algorithms\n",
    "\n",
    "#### Newton's Method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00039-0784b639-59dc-47a4-8e21-6212844d588e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "- Approximates roots by setting an initial guess, then iteratively subtracting the function value scaled by the derivative from the latest guess. This eventually provides very precise (if not exact) approximations of roots.\n",
    "- For scalar non-vector functions: $x_{n+1}=x_{n}-{\\frac {f(x_{n})}{f'(x_{n})}}$\n",
    "- For vector functions: $x_{n+1}=x_{n}-J_{F}(x_{n})^{-1}F(x_{n})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00039-f7c3891a-38e3-4769-a897-594b7ea34e36",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1607739761578,
    "output_cleared": false,
    "source_hash": "9d8b42eb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case: vector function, single variable\n",
      "Should get root of 5\n",
      "(array([5.]), array([[6.17159657e-10],\n",
      "       [6.17159657e-11]]))\n",
      "\n",
      "\n",
      "Case: vector function, multple variables\n",
      "Should get roots of 1 and 1\n",
      "(array([1., 1.]), array([[1.33226763e-15],\n",
      "       [1.33226763e-15]]))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from socialAD.root_finding import newton\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "### Tests of Newton ###\n",
    "\n",
    "print('Case: vector function, single variable')\n",
    "print('Should get root of 5')\n",
    "functions = [\"x**2 - 25\", \"x - 5\"]\n",
    "print(newton(functions,\"x\",[50]))\n",
    "print('\\n')\n",
    "\n",
    "print('Case: vector function, multple variables')\n",
    "print('Should get roots of 1 and 1')\n",
    "functions = [\"x + y - 2\", \"x - y\"]\n",
    "print(newton(functions,[\"x\",\"y\"],[4,4]))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00039-8112c54b-6bc8-4e1e-9843-a14609a4adca",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "#### Broyden's Method\n",
    "\n",
    "- This method is extremely similar to Newton's method, except that it employs finite differences after the first step of the Newton iteration. So, for a non-vector function, it computes finite differences at each iteration after the first. For vector functions, it computes a finitely-updated Jacobian at each iteration after the first.\n",
    "- Mostly used in applications in which the Jacobian is computationally expensive to calculate. This method saves the machine from having to calculate a new Jacobian at each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00040-b8c714ab-0535-4bf6-a32c-c2dd74744a8f",
    "deepnote_cell_type": "code",
    "execution_millis": 51,
    "execution_start": 1607739762713,
    "output_cleared": false,
    "source_hash": "b1c50f3c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case: non-vector function, multiple variables\n",
      "Should get roots of 2.53 and -14.29\n",
      "(array([  2.52688749, -14.29006302]), array([-7.98751429e-08]))\n",
      "\n",
      "\n",
      "Case: vector function, single variable\n",
      "Should get root of 5\n",
      "(array([5.00000001]), array([[9.10860187e-08],\n",
      "       [9.10860187e-09]]))\n",
      "\n",
      "\n",
      "Case: vector function, multple variables\n",
      "Should get roots of 1 and 1\n",
      "(array([1., 1.]), array([[1.33226763e-15],\n",
      "       [1.33226763e-15]]))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from socialAD.root_finding import broyden\n",
    "import numpy as np \n",
    "\n",
    "### Tests of broyden ###\n",
    "\n",
    "print('Case: non-vector function, multiple variables')\n",
    "print('Should get roots of 2.53 and -14.29')\n",
    "print(broyden(\"y + x**3 + 3*x**2 - 21\",[\"x\",\"y\"],[3, 7]))\n",
    "print('\\n')\n",
    "\n",
    "print('Case: vector function, single variable')\n",
    "print('Should get root of 5')\n",
    "functions = [\"x**2 - 25\", \"x - 5\"]\n",
    "print(broyden(functions,\"x\",[50]))\n",
    "print('\\n')\n",
    "\n",
    "print('Case: vector function, multple variables')\n",
    "print('Should get roots of 1 and 1')\n",
    "functions = [\"x + y - 2\", \"x - y\"]\n",
    "print(broyden(functions,[\"x\",\"y\"],[4,4]))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-d05bbc6a-101b-4671-8e05-576f63379f82",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Gradient Descent & BFGS\n",
    "#### One variable \n",
    "\n",
    "- **Gradient Descent**\n",
    "    - Common in the world of machine learning, gradient descent steps through the steepest gradient drop direction until the method finds a stationary point.\n",
    "    - Our implementation allows the user to change the steps size and to use backtrack line search.\n",
    "- **BFGS**\n",
    "    - BFGS is an iterative method for solving unconstrained nonlinear optimization problems. Instead of directly solving for the Hessian matrix, we just approximate it.  We basically follow the descent direction by preconditioning the gradient with curvature information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00025-eb388ba0-9b83-404f-a715-f6218256fe05",
    "deepnote_cell_type": "code",
    "execution_millis": 3,
    "execution_start": 1607728358908,
    "output_cleared": false,
    "source_hash": "91417f41",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socialAD.forward as fw\n",
    "import socialAD.gradient as gd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def generate_timer(function):\n",
    "    def with_timer():\n",
    "        t_start = time.monotonic()\n",
    "        function\n",
    "        t_stop = time.monotonic()\n",
    "        print( f'Time elapsed: {t_stop - t_start} seconds ')\n",
    "        print('--------------------------------------------')\n",
    "    return with_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00026-5a5e6d2b-921f-491f-83b0-274e18caacde",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1607728542622,
    "output_cleared": false,
    "source_hash": "e275c4b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables = [\"x\"]\n",
    "f = \"(x+5)**2 \"\n",
    "cur_x = [3]\n",
    "rate = 0.1\n",
    "precision = 0.000001\n",
    "previous_step_size = 1\n",
    "max_iters = 10000\n",
    "iters = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00026-310289f7-59c4-4f70-92c0-3b6719907073",
    "deepnote_cell_type": "code",
    "execution_millis": 1,
    "execution_start": 1607728624130,
    "output_cleared": false,
    "source_hash": "48f21e94",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "GRADIENT DESCENT\n",
      "============================================\n",
      "Iteration 66\n",
      "The local minimum occurs at [-4.99999679]\n",
      "Time elapsed: 2.720000000788758e-07 seconds \n",
      "--------------------------------------------\n",
      "============================================\n",
      "GD WITH BACKTRACK LINE SEARCH\n",
      "============================================\n",
      "Iteration 14\n",
      "The local minimum occurs at [-4.99999985]\n",
      "Time elapsed: 1.750000000466656e-07 seconds \n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('============================================')\n",
    "print('GRADIENT DESCENT')\n",
    "print('============================================')\n",
    "\n",
    "a = generate_timer(gd.gradient_descent(variables, f, cur_x, rate, precision, previous_step_size, max_iters))\n",
    "a()\n",
    "\n",
    "print('============================================')\n",
    "print('GD WITH BACKTRACK LINE SEARCH')\n",
    "print('============================================')\n",
    "\n",
    "a = generate_timer(gd.gd_backtrack(variables, f, cur_x, precision, previous_step_size, max_iters))\n",
    "a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00024-ae182b95-c8ae-476a-b3b6-24f546a16192",
    "deepnote_cell_type": "code",
    "execution_millis": 5,
    "execution_start": 1607728625231,
    "output_cleared": false,
    "source_hash": "2e2e6c2e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "BFGS\n",
      "============================================\n",
      "Iteration 66\n",
      "The local minimum occurs at [-4.99999679]\n",
      "Time elapsed: 1.9200000000996198e-07 seconds \n",
      "--------------------------------------------\n",
      "============================================\n",
      "BFGS WITH BACKTRACK LINE SEARCH\n",
      "============================================\n",
      "Iteration 14\n",
      "The local minimum occurs at [-4.99999985]\n",
      "Time elapsed: 2.109999999166945e-07 seconds \n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('============================================')\n",
    "print('BFGS')\n",
    "print('============================================')\n",
    "a = generate_timer(gd.BFGS(variables, f, cur_x, precision, max_iters))\n",
    "a()\n",
    "print('============================================')\n",
    "print('BFGS WITH BACKTRACK LINE SEARCH')\n",
    "print('============================================')\n",
    "a = generate_timer(gd.BFGS_backtrack(variables, f, cur_x, precision, max_iters))\n",
    "a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-57d3938f-17d7-468c-8396-c8ce23d1f85d",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Gradient Descent & BFGS\n",
    "#### Multivariable mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "00026-e27952fb-79a2-4888-aa13-1bde863c90ea",
    "deepnote_cell_type": "code",
    "execution_millis": 12,
    "execution_start": 1607728545682,
    "output_cleared": false,
    "source_hash": "58be2125",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "GRADIENT DESCENT\n",
      "============================================\n",
      "Iteration 66\n",
      "The local minimum occurs at [-4.99999679e+00  4.01734511e-07]\n",
      "Time elapsed: 3.1899999997087036e-07 seconds \n",
      "--------------------------------------------\n",
      "============================================\n",
      "GD WITH BACKTRACK LINE SEARCH\n",
      "============================================\n",
      "Iteration 14\n",
      "The local minimum occurs at [-4.99999985e+00  1.82059120e-08]\n",
      "Time elapsed: 1.0830000000128237e-06 seconds \n",
      "--------------------------------------------\n",
      "============================================\n",
      "BFGS\n",
      "============================================\n",
      "Iteration 66\n",
      "The local minimum occurs at [-4.99999684e+00  3.94944181e-07]\n",
      "Time elapsed: 1.5500000005719272e-07 seconds \n",
      "--------------------------------------------\n",
      "============================================\n",
      "BFGS WITH BACKTRACK LINE SEARCH\n",
      "============================================\n",
      "Iteration 14\n",
      "The local minimum occurs at [-4.99999985e+00  1.83903042e-08]\n",
      "Time elapsed: 1.7400000007494754e-07 seconds \n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "variables = [\"x\",\"y\"]\n",
    "f = \"(x+5)**2 + y**2\"\n",
    "cur_x = [3, 1]\n",
    "\n",
    "print('============================================')\n",
    "print('GRADIENT DESCENT')\n",
    "print('============================================')\n",
    "\n",
    "a = generate_timer(gd.gradient_descent(variables, f, cur_x, rate, precision, previous_step_size, max_iters))\n",
    "a()\n",
    "\n",
    "print('============================================')\n",
    "print('GD WITH BACKTRACK LINE SEARCH')\n",
    "print('============================================')\n",
    "\n",
    "a = generate_timer(gd.gd_backtrack(variables, f, cur_x, precision, previous_step_size, max_iters))\n",
    "a()\n",
    "\n",
    "print('============================================')\n",
    "print('BFGS')\n",
    "print('============================================')\n",
    "a  = generate_timer(gd.BFGS(variables, f, cur_x, precision, max_iters))\n",
    "a()\n",
    "print('============================================')\n",
    "print('BFGS WITH BACKTRACK LINE SEARCH')\n",
    "print('============================================')\n",
    "a = generate_timer(gd.BFGS_backtrack(variables, f, cur_x, precision, max_iters))\n",
    "a()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-5500cdc5-32d9-473a-bd58-65d9d0bee2bb",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "## Section IV: Conclusion & Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00033-23e1275a-c73d-4f3c-9652-646e5665b0c5",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "What we have delivered so far... \n",
    "\n",
    "* Auto-diff from scratch with various optimization & root finding algorithms \n",
    "\n",
    "Advantages of our package\n",
    "\n",
    "* Rigorous, user-friendly, and customizable \n",
    "\n",
    " ![rxn_rate](img/summary_figure.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-3e253be6-e128-440a-9b56-d3df310c6f69",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "### Real world aplications \n",
    "* Economics \n",
    "    * Various econometric applications \n",
    "    * For example: a Fisher Market problem (spending constraint utilities)\n",
    " ![rxn_rate](img/fisher_1.png)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-880a080d-ec94-426c-8e19-e9323516dfc6",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "\n",
    "* Environemental Engineering\n",
    "    * Inverse modeling: estimating emissions based on measured concentrations and prior information\n",
    "\n",
    " ![rxn_rate](img/inverse.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-632b7821-ebf1-4278-bf00-e9ca5c876230",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "* Chemistry\n",
    "    * Estimate reaction rates \n",
    " ![rxn_rate](img/rxn_rate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00040-6cbbf200-a893-4393-ae65-6bdc9e9ce86c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Hopefully, you are interested in our package by now. Feel free to download our package using\n",
    "\n",
    "`$ pip install socialAD`"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "a1c0ef0e-aa2f-4685-b366-97641aa4e788",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
